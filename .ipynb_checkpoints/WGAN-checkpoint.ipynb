{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,LeakyReLU, Activation, Dense, Conv2D, Flatten, Reshape, Conv2DTranspose,BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"..\")\n",
    "# from lib import gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(generator, noise_input, noise_label=None, noise_codes=None, show=False, step=0, model_name=\"gan\"):\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
    "    rows = int(math.sqrt(noise_input.shape[0]))\n",
    "    if noise_label is not None:\n",
    "        noise_input = [noise_input, noise_label]\n",
    "        if noise_codes is not None:\n",
    "            noise_input += noise_codes\n",
    "\n",
    "    images = generator.predict(noise_input)\n",
    "    plt.figure(figsize=(2.2, 2.2))\n",
    "    num_images = images.shape[0]\n",
    "    image_size = images.shape[1]\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, rows, i + 1)\n",
    "        image = np.reshape(images[i], [image_size, image_size])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(filename)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST dataset\n",
    "(x_train, _), (_, _) = mnist.load_data()\n",
    "# reshape data for CNN as (28, 28, 1) and normalize\n",
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"wgan_mnist\"\n",
    "# network parameters\n",
    "# the latent or z vector is 100-dim\n",
    "latent_size = 100\n",
    "# hyper parameters from WGAN paper [2]\n",
    "n_critic = 5\n",
    "clip_value = 0.01\n",
    "batch_size = 64\n",
    "lr = 5e-5\n",
    "train_steps = 40000\n",
    "input_shape = (image_size, image_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_label, y_pred):\n",
    "    return -K.mean(y_label * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 32)        832       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 64)          51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 4097      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,080,577\n",
      "Trainable params: 1,080,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build discriminator model\n",
    "inputs = Input(shape=input_shape, name='discriminator_input')\n",
    "\n",
    "x = LeakyReLU(alpha=0.2)(inputs)\n",
    "x = Conv2D(filters=32, kernel_size=5, strides=2, padding='same')(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=5, strides=2, padding='same')(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=5, strides=2, padding='same')(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "x = Conv2D(filters=256, kernel_size=5, strides=1, padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(1)(x)\n",
    "# WGAN uses linear activation in paper [2]\n",
    "outputs = Activation(activation='linear')(outputs)\n",
    "discriminator = Model(inputs, outputs, name='discriminator')\n",
    "\n",
    "optimizer = RMSprop(lr=lr)\n",
    "# WGAN discriminator uses wassertein loss\n",
    "discriminator.compile(loss=wasserstein_loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_input (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 49)                4949      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 1)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 1)           4         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 7, 7, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 14, 14, 128)       3328      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 266,074\n",
      "Trainable params: 265,624\n",
      "Non-trainable params: 450\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build generator model\n",
    "input_shape = (latent_size, )\n",
    "image_resize = image_size // 4\n",
    "\n",
    "inputs = Input(shape=input_shape, name='z_input')\n",
    "x = Dense(image_resize * image_resize * 1)(inputs)\n",
    "x = Reshape((image_resize, image_resize, 1))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2DTranspose(filters=128, kernel_size=5, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2DTranspose(filters=64, kernel_size=5, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2DTranspose(filters=32, kernel_size=5, strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2DTranspose(filters=1, kernel_size=5, strides=1, padding='same')(x)\n",
    "x = Activation(activation='sigmoid')(x)\n",
    "\n",
    "generator = Model(inputs, x, name='generator')\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wgan_mnist\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_input (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "generator (Model)            (None, 28, 28, 1)         266074    \n",
      "_________________________________________________________________\n",
      "discriminator (Model)        (None, 1)                 1080577   \n",
      "=================================================================\n",
      "Total params: 1,346,651\n",
      "Trainable params: 265,624\n",
      "Non-trainable params: 1,081,027\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build adversarial model = generator + discriminator\n",
    "# freeze the weights of discriminator during adversarial training\n",
    "discriminator.trainable = False\n",
    "adversarial = Model(inputs, discriminator(generator(inputs)), name=model_name)\n",
    "adversarial.compile(loss=wasserstein_loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "adversarial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [discriminator loss: 0.015030, acc: 0.000000] [adversarial loss: -0.000273, acc: 0.000000]\n",
      "1: [discriminator loss: 0.000001, acc: 0.000000] [adversarial loss: -0.000154, acc: 0.000000]\n",
      "2: [discriminator loss: -0.000145, acc: 0.000000] [adversarial loss: 0.000062, acc: 0.000000]\n",
      "3: [discriminator loss: -0.000413, acc: 0.000000] [adversarial loss: 0.000465, acc: 0.000000]\n",
      "4: [discriminator loss: -0.000969, acc: 0.000000] [adversarial loss: 0.001379, acc: 0.000000]\n",
      "5: [discriminator loss: -0.002326, acc: 0.000000] [adversarial loss: 0.003738, acc: 0.000000]\n",
      "6: [discriminator loss: -0.005621, acc: 0.000000] [adversarial loss: 0.008925, acc: 0.000000]\n",
      "7: [discriminator loss: -0.013330, acc: 0.000000] [adversarial loss: 0.019076, acc: 0.000000]\n",
      "8: [discriminator loss: -0.026463, acc: 0.000000] [adversarial loss: 0.033314, acc: 0.000000]\n",
      "9: [discriminator loss: -0.049825, acc: 0.000000] [adversarial loss: 0.054909, acc: 0.000000]\n",
      "10: [discriminator loss: -0.082861, acc: 0.000000] [adversarial loss: 0.081427, acc: 0.000000]\n",
      "11: [discriminator loss: -0.130839, acc: 0.000000] [adversarial loss: 0.111655, acc: 0.000000]\n",
      "12: [discriminator loss: -0.192459, acc: 0.000000] [adversarial loss: 0.145079, acc: 0.000000]\n",
      "13: [discriminator loss: -0.274026, acc: 0.000000] [adversarial loss: 0.176799, acc: 0.000000]\n",
      "14: [discriminator loss: -0.377071, acc: 0.000000] [adversarial loss: 0.212251, acc: 0.000000]\n",
      "15: [discriminator loss: -0.510039, acc: 0.000000] [adversarial loss: 0.235971, acc: 0.000000]\n",
      "16: [discriminator loss: -0.670755, acc: 0.053125] [adversarial loss: 0.251699, acc: 0.000000]\n",
      "17: [discriminator loss: -0.848875, acc: 0.168750] [adversarial loss: 0.252963, acc: 0.000000]\n",
      "18: [discriminator loss: -1.080298, acc: 0.254688] [adversarial loss: 0.208969, acc: 0.000000]\n",
      "19: [discriminator loss: -1.368869, acc: 0.334375] [adversarial loss: 0.158137, acc: 0.000000]\n",
      "20: [discriminator loss: -1.686959, acc: 0.367188] [adversarial loss: 0.069349, acc: 0.000000]\n",
      "21: [discriminator loss: -2.044049, acc: 0.367188] [adversarial loss: -0.011742, acc: 0.000000]\n",
      "22: [discriminator loss: -2.516412, acc: 0.404687] [adversarial loss: -0.144138, acc: 0.000000]\n",
      "23: [discriminator loss: -2.973229, acc: 0.403125] [adversarial loss: -0.328043, acc: 0.093750]\n",
      "24: [discriminator loss: -3.496100, acc: 0.396875] [adversarial loss: -0.569947, acc: 0.718750]\n",
      "25: [discriminator loss: -4.141767, acc: 0.418750] [adversarial loss: -0.903110, acc: 1.000000]\n",
      "26: [discriminator loss: -4.864262, acc: 0.420312] [adversarial loss: -1.260468, acc: 1.000000]\n",
      "27: [discriminator loss: -5.588810, acc: 0.398438] [adversarial loss: -1.670247, acc: 1.000000]\n",
      "28: [discriminator loss: -6.486652, acc: 0.412500] [adversarial loss: -2.253630, acc: 1.000000]\n",
      "29: [discriminator loss: -7.546264, acc: 0.432812] [adversarial loss: -2.723995, acc: 1.000000]\n",
      "30: [discriminator loss: -8.656023, acc: 0.442188] [adversarial loss: -3.233576, acc: 1.000000]\n",
      "31: [discriminator loss: -9.821252, acc: 0.428125] [adversarial loss: -3.889932, acc: 1.000000]\n",
      "32: [discriminator loss: -11.204899, acc: 0.442188] [adversarial loss: -4.598342, acc: 1.000000]\n",
      "33: [discriminator loss: -12.674826, acc: 0.431250] [adversarial loss: -5.255556, acc: 1.000000]\n",
      "34: [discriminator loss: -13.987489, acc: 0.410938] [adversarial loss: -5.955892, acc: 1.000000]\n",
      "35: [discriminator loss: -15.356256, acc: 0.412500] [adversarial loss: -6.809649, acc: 1.000000]\n",
      "36: [discriminator loss: -17.127674, acc: 0.404687] [adversarial loss: -7.686211, acc: 1.000000]\n",
      "37: [discriminator loss: -19.235173, acc: 0.417187] [adversarial loss: -8.582476, acc: 1.000000]\n",
      "38: [discriminator loss: -21.221882, acc: 0.420312] [adversarial loss: -9.529882, acc: 1.000000]\n",
      "39: [discriminator loss: -23.376923, acc: 0.418750] [adversarial loss: -10.516863, acc: 1.000000]\n",
      "40: [discriminator loss: -25.495460, acc: 0.396875] [adversarial loss: -11.453020, acc: 1.000000]\n",
      "41: [discriminator loss: -28.075900, acc: 0.410938] [adversarial loss: -12.400141, acc: 1.000000]\n",
      "42: [discriminator loss: -30.545670, acc: 0.418750] [adversarial loss: -13.542210, acc: 1.000000]\n",
      "43: [discriminator loss: -33.250124, acc: 0.406250] [adversarial loss: -14.499125, acc: 1.000000]\n",
      "44: [discriminator loss: -35.675051, acc: 0.393750] [adversarial loss: -15.611884, acc: 1.000000]\n",
      "45: [discriminator loss: -38.340061, acc: 0.400000] [adversarial loss: -16.629225, acc: 1.000000]\n",
      "46: [discriminator loss: -41.482094, acc: 0.393750] [adversarial loss: -17.635788, acc: 1.000000]\n",
      "47: [discriminator loss: -43.791209, acc: 0.375000] [adversarial loss: -18.515617, acc: 1.000000]\n",
      "48: [discriminator loss: -46.447814, acc: 0.360938] [adversarial loss: -19.811476, acc: 1.000000]\n",
      "49: [discriminator loss: -49.821078, acc: 0.384375] [adversarial loss: -20.501173, acc: 1.000000]\n",
      "50: [discriminator loss: -51.969849, acc: 0.343750] [adversarial loss: -21.492085, acc: 1.000000]\n",
      "51: [discriminator loss: -57.296748, acc: 0.382812] [adversarial loss: -22.279053, acc: 1.000000]\n",
      "52: [discriminator loss: -59.055951, acc: 0.359375] [adversarial loss: -22.965162, acc: 1.000000]\n",
      "53: [discriminator loss: -60.913515, acc: 0.326562] [adversarial loss: -23.211010, acc: 1.000000]\n",
      "54: [discriminator loss: -64.773723, acc: 0.321875] [adversarial loss: -23.831253, acc: 1.000000]\n",
      "55: [discriminator loss: -68.118042, acc: 0.325000] [adversarial loss: -23.747223, acc: 1.000000]\n",
      "56: [discriminator loss: -70.589802, acc: 0.320312] [adversarial loss: -23.541908, acc: 1.000000]\n",
      "57: [discriminator loss: -75.379066, acc: 0.337500] [adversarial loss: -23.325800, acc: 1.000000]\n",
      "58: [discriminator loss: -75.703198, acc: 0.287500] [adversarial loss: -22.752310, acc: 1.000000]\n",
      "59: [discriminator loss: -78.161370, acc: 0.282813] [adversarial loss: -21.874523, acc: 1.000000]\n",
      "60: [discriminator loss: -82.345293, acc: 0.287500] [adversarial loss: -21.203831, acc: 1.000000]\n",
      "61: [discriminator loss: -84.015043, acc: 0.260937] [adversarial loss: -20.180883, acc: 1.000000]\n",
      "62: [discriminator loss: -85.807881, acc: 0.242188] [adversarial loss: -19.173954, acc: 1.000000]\n",
      "63: [discriminator loss: -90.444755, acc: 0.278125] [adversarial loss: -17.759085, acc: 1.000000]\n",
      "64: [discriminator loss: -90.200663, acc: 0.225000] [adversarial loss: -16.658318, acc: 1.000000]\n",
      "65: [discriminator loss: -92.857262, acc: 0.232813] [adversarial loss: -15.139834, acc: 1.000000]\n",
      "66: [discriminator loss: -94.561481, acc: 0.201563] [adversarial loss: -14.146210, acc: 1.000000]\n",
      "67: [discriminator loss: -98.322861, acc: 0.228125] [adversarial loss: -12.287164, acc: 1.000000]\n",
      "68: [discriminator loss: -99.601321, acc: 0.226562] [adversarial loss: -10.627731, acc: 1.000000]\n",
      "69: [discriminator loss: -101.729023, acc: 0.206250] [adversarial loss: -9.223101, acc: 1.000000]\n",
      "70: [discriminator loss: -101.502552, acc: 0.185938] [adversarial loss: -7.774460, acc: 1.000000]\n",
      "71: [discriminator loss: -101.188516, acc: 0.182812] [adversarial loss: -6.030778, acc: 1.000000]\n",
      "72: [discriminator loss: -101.842445, acc: 0.167187] [adversarial loss: -4.807536, acc: 0.875000]\n",
      "73: [discriminator loss: -103.748671, acc: 0.175000] [adversarial loss: -4.673575, acc: 0.687500]\n",
      "74: [discriminator loss: -105.185081, acc: 0.165625] [adversarial loss: -2.825335, acc: 0.500000]\n",
      "75: [discriminator loss: -102.342560, acc: 0.164062] [adversarial loss: -1.459325, acc: 0.500000]\n",
      "76: [discriminator loss: -104.317436, acc: 0.156250] [adversarial loss: -3.700769, acc: 0.578125]\n",
      "77: [discriminator loss: -105.335332, acc: 0.140625] [adversarial loss: -3.092316, acc: 0.406250]\n",
      "78: [discriminator loss: -106.885170, acc: 0.153125] [adversarial loss: -3.810687, acc: 0.593750]\n",
      "79: [discriminator loss: -102.626061, acc: 0.123438] [adversarial loss: -3.956192, acc: 0.562500]\n",
      "80: [discriminator loss: -105.063009, acc: 0.125000] [adversarial loss: -7.724297, acc: 0.578125]\n",
      "81: [discriminator loss: -106.152808, acc: 0.126562] [adversarial loss: -11.641711, acc: 0.765625]\n",
      "82: [discriminator loss: -106.909930, acc: 0.128125] [adversarial loss: -16.448139, acc: 0.828125]\n",
      "83: [discriminator loss: -106.891735, acc: 0.120313] [adversarial loss: -22.837444, acc: 0.875000]\n",
      "84: [discriminator loss: -106.410065, acc: 0.101562] [adversarial loss: -32.421417, acc: 0.984375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85: [discriminator loss: -108.988280, acc: 0.104688] [adversarial loss: -40.464615, acc: 1.000000]\n",
      "86: [discriminator loss: -113.913955, acc: 0.117188] [adversarial loss: -47.328335, acc: 1.000000]\n",
      "87: [discriminator loss: -112.178378, acc: 0.109375] [adversarial loss: -50.422173, acc: 1.000000]\n",
      "88: [discriminator loss: -111.910949, acc: 0.093750] [adversarial loss: -53.114223, acc: 1.000000]\n",
      "89: [discriminator loss: -118.611156, acc: 0.118750] [adversarial loss: -54.235588, acc: 1.000000]\n",
      "90: [discriminator loss: -110.760719, acc: 0.090625] [adversarial loss: -56.013092, acc: 1.000000]\n",
      "91: [discriminator loss: -113.813723, acc: 0.098437] [adversarial loss: -57.177334, acc: 1.000000]\n",
      "92: [discriminator loss: -115.851353, acc: 0.090625] [adversarial loss: -58.051231, acc: 1.000000]\n",
      "93: [discriminator loss: -112.377261, acc: 0.087500] [adversarial loss: -59.101784, acc: 1.000000]\n",
      "94: [discriminator loss: -115.363040, acc: 0.078125] [adversarial loss: -59.945530, acc: 1.000000]\n",
      "95: [discriminator loss: -110.306221, acc: 0.084375] [adversarial loss: -60.591625, acc: 1.000000]\n",
      "96: [discriminator loss: -117.437503, acc: 0.093750] [adversarial loss: -61.491432, acc: 1.000000]\n",
      "97: [discriminator loss: -116.345527, acc: 0.075000] [adversarial loss: -62.021805, acc: 1.000000]\n",
      "98: [discriminator loss: -110.755530, acc: 0.076563] [adversarial loss: -62.817165, acc: 1.000000]\n",
      "99: [discriminator loss: -112.609943, acc: 0.087500] [adversarial loss: -63.374130, acc: 1.000000]\n",
      "100: [discriminator loss: -112.138055, acc: 0.075000] [adversarial loss: -63.765820, acc: 1.000000]\n",
      "101: [discriminator loss: -110.730611, acc: 0.070312] [adversarial loss: -64.302689, acc: 1.000000]\n",
      "102: [discriminator loss: -109.817146, acc: 0.067187] [adversarial loss: -64.964325, acc: 1.000000]\n",
      "103: [discriminator loss: -110.529138, acc: 0.076563] [adversarial loss: -65.459595, acc: 1.000000]\n",
      "104: [discriminator loss: -112.968053, acc: 0.073438] [adversarial loss: -65.961090, acc: 1.000000]\n",
      "105: [discriminator loss: -112.563942, acc: 0.078125] [adversarial loss: -66.335022, acc: 1.000000]\n",
      "106: [discriminator loss: -111.453270, acc: 0.076563] [adversarial loss: -66.849709, acc: 1.000000]\n",
      "107: [discriminator loss: -108.215603, acc: 0.067187] [adversarial loss: -67.300499, acc: 1.000000]\n",
      "108: [discriminator loss: -106.384299, acc: 0.068750] [adversarial loss: -67.801872, acc: 1.000000]\n",
      "109: [discriminator loss: -104.144827, acc: 0.056250] [adversarial loss: -68.202866, acc: 1.000000]\n",
      "110: [discriminator loss: -105.512267, acc: 0.078125] [adversarial loss: -68.642555, acc: 1.000000]\n",
      "111: [discriminator loss: -107.073338, acc: 0.076563] [adversarial loss: -68.927795, acc: 1.000000]\n",
      "112: [discriminator loss: -105.068042, acc: 0.057813] [adversarial loss: -69.372261, acc: 1.000000]\n",
      "113: [discriminator loss: -100.224383, acc: 0.050000] [adversarial loss: -69.719917, acc: 1.000000]\n",
      "114: [discriminator loss: -96.472527, acc: 0.050000] [adversarial loss: -70.235420, acc: 1.000000]\n",
      "115: [discriminator loss: -95.103827, acc: 0.048438] [adversarial loss: -70.460449, acc: 1.000000]\n",
      "116: [discriminator loss: -96.919521, acc: 0.048438] [adversarial loss: -70.930099, acc: 1.000000]\n",
      "117: [discriminator loss: -101.194156, acc: 0.070312] [adversarial loss: -71.284103, acc: 1.000000]\n",
      "118: [discriminator loss: -96.907534, acc: 0.045312] [adversarial loss: -71.625580, acc: 1.000000]\n",
      "119: [discriminator loss: -96.592168, acc: 0.065625] [adversarial loss: -71.928131, acc: 1.000000]\n",
      "120: [discriminator loss: -90.792893, acc: 0.065625] [adversarial loss: -72.232780, acc: 1.000000]\n",
      "121: [discriminator loss: -92.981559, acc: 0.051562] [adversarial loss: -72.578171, acc: 1.000000]\n",
      "122: [discriminator loss: -88.861162, acc: 0.070312] [adversarial loss: -72.812904, acc: 1.000000]\n",
      "123: [discriminator loss: -92.804079, acc: 0.073438] [adversarial loss: -73.038452, acc: 1.000000]\n",
      "124: [discriminator loss: -87.654208, acc: 0.057813] [adversarial loss: -73.419601, acc: 1.000000]\n",
      "125: [discriminator loss: -87.879536, acc: 0.050000] [adversarial loss: -73.764359, acc: 1.000000]\n",
      "126: [discriminator loss: -83.690650, acc: 0.064062] [adversarial loss: -74.011490, acc: 1.000000]\n",
      "127: [discriminator loss: -80.899105, acc: 0.053125] [adversarial loss: -74.308754, acc: 1.000000]\n",
      "128: [discriminator loss: -83.047382, acc: 0.035937] [adversarial loss: -74.569458, acc: 1.000000]\n",
      "129: [discriminator loss: -81.143795, acc: 0.059375] [adversarial loss: -74.804840, acc: 1.000000]\n",
      "130: [discriminator loss: -81.776777, acc: 0.048438] [adversarial loss: -75.035103, acc: 1.000000]\n",
      "131: [discriminator loss: -76.538634, acc: 0.045312] [adversarial loss: -75.270538, acc: 1.000000]\n",
      "132: [discriminator loss: -74.044733, acc: 0.043750] [adversarial loss: -75.546318, acc: 1.000000]\n",
      "133: [discriminator loss: -79.117551, acc: 0.050000] [adversarial loss: -75.789467, acc: 1.000000]\n",
      "134: [discriminator loss: -75.722271, acc: 0.042188] [adversarial loss: -76.023117, acc: 1.000000]\n",
      "135: [discriminator loss: -76.145942, acc: 0.050000] [adversarial loss: -76.229019, acc: 1.000000]\n",
      "136: [discriminator loss: -73.296178, acc: 0.045312] [adversarial loss: -76.528275, acc: 1.000000]\n",
      "137: [discriminator loss: -69.383927, acc: 0.031250] [adversarial loss: -76.706451, acc: 1.000000]\n",
      "138: [discriminator loss: -68.701831, acc: 0.053125] [adversarial loss: -76.900879, acc: 1.000000]\n",
      "139: [discriminator loss: -66.750096, acc: 0.035937] [adversarial loss: -77.137802, acc: 1.000000]\n",
      "140: [discriminator loss: -70.172231, acc: 0.054688] [adversarial loss: -77.238266, acc: 1.000000]\n",
      "141: [discriminator loss: -64.332486, acc: 0.043750] [adversarial loss: -77.475143, acc: 1.000000]\n",
      "142: [discriminator loss: -63.653519, acc: 0.043750] [adversarial loss: -77.686584, acc: 1.000000]\n",
      "143: [discriminator loss: -63.629965, acc: 0.053125] [adversarial loss: -77.819008, acc: 1.000000]\n",
      "144: [discriminator loss: -57.127654, acc: 0.032813] [adversarial loss: -77.964180, acc: 1.000000]\n",
      "145: [discriminator loss: -62.811185, acc: 0.046875] [adversarial loss: -78.072479, acc: 1.000000]\n",
      "146: [discriminator loss: -58.533638, acc: 0.050000] [adversarial loss: -78.220291, acc: 1.000000]\n",
      "147: [discriminator loss: -53.147976, acc: 0.039062] [adversarial loss: -78.348511, acc: 1.000000]\n",
      "148: [discriminator loss: -52.306603, acc: 0.039062] [adversarial loss: -78.456192, acc: 1.000000]\n",
      "149: [discriminator loss: -52.793861, acc: 0.059375] [adversarial loss: -78.527061, acc: 1.000000]\n",
      "150: [discriminator loss: -49.121632, acc: 0.046875] [adversarial loss: -78.662048, acc: 1.000000]\n",
      "151: [discriminator loss: -47.513133, acc: 0.043750] [adversarial loss: -78.689095, acc: 1.000000]\n",
      "152: [discriminator loss: -44.281033, acc: 0.050000] [adversarial loss: -78.708694, acc: 1.000000]\n",
      "153: [discriminator loss: -40.399419, acc: 0.028125] [adversarial loss: -78.745636, acc: 1.000000]\n",
      "154: [discriminator loss: -38.276597, acc: 0.037500] [adversarial loss: -78.726578, acc: 1.000000]\n",
      "155: [discriminator loss: -39.638173, acc: 0.046875] [adversarial loss: -78.618073, acc: 1.000000]\n",
      "156: [discriminator loss: -32.103710, acc: 0.029687] [adversarial loss: -78.521423, acc: 1.000000]\n",
      "157: [discriminator loss: -34.859022, acc: 0.042188] [adversarial loss: -78.380127, acc: 1.000000]\n",
      "158: [discriminator loss: -24.330808, acc: 0.021875] [adversarial loss: -78.215012, acc: 1.000000]\n",
      "159: [discriminator loss: -25.122040, acc: 0.040625] [adversarial loss: -77.959656, acc: 1.000000]\n",
      "160: [discriminator loss: -26.544816, acc: 0.046875] [adversarial loss: -77.720627, acc: 1.000000]\n",
      "161: [discriminator loss: -26.060872, acc: 0.039062] [adversarial loss: -77.412491, acc: 1.000000]\n",
      "162: [discriminator loss: -20.222424, acc: 0.025000] [adversarial loss: -77.109665, acc: 1.000000]\n",
      "163: [discriminator loss: -18.237971, acc: 0.043750] [adversarial loss: -76.692238, acc: 1.000000]\n",
      "164: [discriminator loss: -17.329109, acc: 0.056250] [adversarial loss: -76.296104, acc: 1.000000]\n",
      "165: [discriminator loss: -15.945745, acc: 0.042188] [adversarial loss: -75.884644, acc: 1.000000]\n",
      "166: [discriminator loss: -13.193284, acc: 0.040625] [adversarial loss: -75.405563, acc: 1.000000]\n",
      "167: [discriminator loss: -10.016444, acc: 0.057813] [adversarial loss: -74.844513, acc: 1.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168: [discriminator loss: -9.967733, acc: 0.051562] [adversarial loss: -74.308197, acc: 1.000000]\n",
      "169: [discriminator loss: -8.532911, acc: 0.059375] [adversarial loss: -73.678543, acc: 1.000000]\n",
      "170: [discriminator loss: -5.530589, acc: 0.050000] [adversarial loss: -73.042679, acc: 1.000000]\n",
      "171: [discriminator loss: -5.368523, acc: 0.048438] [adversarial loss: -72.337173, acc: 1.000000]\n",
      "172: [discriminator loss: -5.559027, acc: 0.068750] [adversarial loss: -71.632957, acc: 1.000000]\n",
      "173: [discriminator loss: -2.432058, acc: 0.068750] [adversarial loss: -70.894241, acc: 1.000000]\n",
      "174: [discriminator loss: -2.772424, acc: 0.057813] [adversarial loss: -70.117134, acc: 1.000000]\n",
      "175: [discriminator loss: -0.450908, acc: 0.075000] [adversarial loss: -69.275848, acc: 1.000000]\n",
      "176: [discriminator loss: 2.499207, acc: 0.064062] [adversarial loss: -68.328613, acc: 1.000000]\n",
      "177: [discriminator loss: 1.639951, acc: 0.079687] [adversarial loss: -67.376923, acc: 1.000000]\n",
      "178: [discriminator loss: 2.127780, acc: 0.062500] [adversarial loss: -66.386612, acc: 1.000000]\n",
      "179: [discriminator loss: 1.888607, acc: 0.084375] [adversarial loss: -65.386848, acc: 1.000000]\n",
      "180: [discriminator loss: 4.236915, acc: 0.085938] [adversarial loss: -64.240601, acc: 1.000000]\n",
      "181: [discriminator loss: 4.120465, acc: 0.090625] [adversarial loss: -63.042538, acc: 1.000000]\n",
      "182: [discriminator loss: 3.802525, acc: 0.090625] [adversarial loss: -61.857964, acc: 1.000000]\n",
      "183: [discriminator loss: 1.979792, acc: 0.110937] [adversarial loss: -60.786865, acc: 1.000000]\n",
      "184: [discriminator loss: 5.953304, acc: 0.093750] [adversarial loss: -59.285427, acc: 1.000000]\n",
      "185: [discriminator loss: 3.991408, acc: 0.139063] [adversarial loss: -57.895412, acc: 1.000000]\n",
      "186: [discriminator loss: 3.490140, acc: 0.142187] [adversarial loss: -56.522282, acc: 1.000000]\n",
      "187: [discriminator loss: 1.670942, acc: 0.171875] [adversarial loss: -55.311806, acc: 1.000000]\n",
      "188: [discriminator loss: 4.986723, acc: 0.140625] [adversarial loss: -53.455910, acc: 1.000000]\n",
      "189: [discriminator loss: 2.426482, acc: 0.184375] [adversarial loss: -51.988945, acc: 1.000000]\n",
      "190: [discriminator loss: 3.782470, acc: 0.173437] [adversarial loss: -50.053955, acc: 1.000000]\n",
      "191: [discriminator loss: 3.822809, acc: 0.184375] [adversarial loss: -47.968891, acc: 1.000000]\n",
      "192: [discriminator loss: 2.402386, acc: 0.215625] [adversarial loss: -46.055687, acc: 1.000000]\n",
      "193: [discriminator loss: 1.785715, acc: 0.265625] [adversarial loss: -44.141121, acc: 1.000000]\n",
      "194: [discriminator loss: 0.975108, acc: 0.251563] [adversarial loss: -42.440495, acc: 1.000000]\n",
      "195: [discriminator loss: 1.546160, acc: 0.271875] [adversarial loss: -40.312233, acc: 1.000000]\n",
      "196: [discriminator loss: 0.137932, acc: 0.310937] [adversarial loss: -39.228199, acc: 1.000000]\n",
      "197: [discriminator loss: -0.056037, acc: 0.346875] [adversarial loss: -38.254051, acc: 1.000000]\n",
      "198: [discriminator loss: -0.137890, acc: 0.332813] [adversarial loss: -37.328865, acc: 1.000000]\n",
      "199: [discriminator loss: -0.511445, acc: 0.356250] [adversarial loss: -36.576496, acc: 1.000000]\n",
      "200: [discriminator loss: -0.406558, acc: 0.346875] [adversarial loss: -35.754639, acc: 1.000000]\n",
      "201: [discriminator loss: -0.435086, acc: 0.370312] [adversarial loss: -34.946583, acc: 1.000000]\n",
      "202: [discriminator loss: -1.285625, acc: 0.385937] [adversarial loss: -34.391136, acc: 1.000000]\n",
      "203: [discriminator loss: -1.472667, acc: 0.392188] [adversarial loss: -33.843216, acc: 1.000000]\n",
      "204: [discriminator loss: -1.737746, acc: 0.423438] [adversarial loss: -33.330345, acc: 1.000000]\n",
      "205: [discriminator loss: -1.858862, acc: 0.428125] [adversarial loss: -32.809898, acc: 1.000000]\n",
      "206: [discriminator loss: -1.714634, acc: 0.451562] [adversarial loss: -32.152054, acc: 1.000000]\n",
      "207: [discriminator loss: -2.099058, acc: 0.457813] [adversarial loss: -31.562532, acc: 1.000000]\n",
      "208: [discriminator loss: -2.881773, acc: 0.485938] [adversarial loss: -31.107716, acc: 1.000000]\n",
      "209: [discriminator loss: -2.854057, acc: 0.484375] [adversarial loss: -30.616222, acc: 1.000000]\n",
      "210: [discriminator loss: -3.163231, acc: 0.485938] [adversarial loss: -30.218933, acc: 1.000000]\n",
      "211: [discriminator loss: -3.613556, acc: 0.493750] [adversarial loss: -29.858566, acc: 1.000000]\n",
      "212: [discriminator loss: -4.239915, acc: 0.498437] [adversarial loss: -29.601692, acc: 1.000000]\n",
      "213: [discriminator loss: -4.386181, acc: 0.500000] [adversarial loss: -29.332731, acc: 1.000000]\n",
      "214: [discriminator loss: -4.632199, acc: 0.500000] [adversarial loss: -29.132095, acc: 1.000000]\n",
      "215: [discriminator loss: -5.550421, acc: 0.500000] [adversarial loss: -29.019958, acc: 1.000000]\n",
      "216: [discriminator loss: -6.482215, acc: 0.500000] [adversarial loss: -29.049847, acc: 1.000000]\n",
      "217: [discriminator loss: -6.696456, acc: 0.500000] [adversarial loss: -28.947487, acc: 1.000000]\n",
      "218: [discriminator loss: -7.694786, acc: 0.500000] [adversarial loss: -28.983040, acc: 1.000000]\n",
      "219: [discriminator loss: -8.746235, acc: 0.500000] [adversarial loss: -29.000607, acc: 1.000000]\n",
      "220: [discriminator loss: -10.057483, acc: 0.500000] [adversarial loss: -29.108740, acc: 1.000000]\n",
      "221: [discriminator loss: -11.142702, acc: 0.500000] [adversarial loss: -29.162590, acc: 1.000000]\n",
      "222: [discriminator loss: -12.392743, acc: 0.500000] [adversarial loss: -29.214233, acc: 1.000000]\n",
      "223: [discriminator loss: -13.724666, acc: 0.500000] [adversarial loss: -29.315464, acc: 1.000000]\n",
      "224: [discriminator loss: -15.195234, acc: 0.500000] [adversarial loss: -29.434624, acc: 1.000000]\n",
      "225: [discriminator loss: -16.992743, acc: 0.500000] [adversarial loss: -29.589294, acc: 1.000000]\n",
      "226: [discriminator loss: -18.384054, acc: 0.500000] [adversarial loss: -29.787968, acc: 1.000000]\n",
      "227: [discriminator loss: -20.573151, acc: 0.500000] [adversarial loss: -30.108715, acc: 1.000000]\n",
      "228: [discriminator loss: -23.206685, acc: 0.500000] [adversarial loss: -30.684895, acc: 1.000000]\n",
      "229: [discriminator loss: -25.410811, acc: 0.500000] [adversarial loss: -31.950590, acc: 1.000000]\n",
      "230: [discriminator loss: -28.367625, acc: 0.500000] [adversarial loss: -34.545532, acc: 1.000000]\n",
      "231: [discriminator loss: -30.929712, acc: 0.500000] [adversarial loss: -39.729958, acc: 1.000000]\n",
      "232: [discriminator loss: -34.323662, acc: 0.500000] [adversarial loss: -47.449348, acc: 1.000000]\n",
      "233: [discriminator loss: -37.459374, acc: 0.500000] [adversarial loss: -56.869797, acc: 1.000000]\n",
      "234: [discriminator loss: -40.360246, acc: 0.500000] [adversarial loss: -66.341522, acc: 1.000000]\n",
      "235: [discriminator loss: -43.159113, acc: 0.500000] [adversarial loss: -79.000092, acc: 1.000000]\n",
      "236: [discriminator loss: -45.261353, acc: 0.500000] [adversarial loss: -90.364777, acc: 1.000000]\n",
      "237: [discriminator loss: -48.263691, acc: 0.500000] [adversarial loss: -102.616188, acc: 1.000000]\n",
      "238: [discriminator loss: -52.102922, acc: 0.500000] [adversarial loss: -115.812599, acc: 1.000000]\n",
      "239: [discriminator loss: -54.816999, acc: 0.500000] [adversarial loss: -127.839966, acc: 1.000000]\n",
      "240: [discriminator loss: -57.564612, acc: 0.500000] [adversarial loss: -141.260803, acc: 1.000000]\n",
      "241: [discriminator loss: -61.908967, acc: 0.500000] [adversarial loss: -153.661438, acc: 1.000000]\n",
      "242: [discriminator loss: -62.087253, acc: 0.500000] [adversarial loss: -166.106323, acc: 1.000000]\n",
      "243: [discriminator loss: -70.249027, acc: 0.500000] [adversarial loss: -178.423340, acc: 1.000000]\n",
      "244: [discriminator loss: -69.329327, acc: 0.500000] [adversarial loss: -191.377319, acc: 1.000000]\n",
      "245: [discriminator loss: -75.197586, acc: 0.500000] [adversarial loss: -203.682098, acc: 1.000000]\n",
      "246: [discriminator loss: -78.490510, acc: 0.500000] [adversarial loss: -215.975281, acc: 1.000000]\n",
      "247: [discriminator loss: -79.861336, acc: 0.500000] [adversarial loss: -227.191101, acc: 1.000000]\n",
      "248: [discriminator loss: -84.148576, acc: 0.500000] [adversarial loss: -240.214233, acc: 1.000000]\n",
      "249: [discriminator loss: -84.954373, acc: 0.500000] [adversarial loss: -251.300751, acc: 1.000000]\n",
      "250: [discriminator loss: -89.615098, acc: 0.500000] [adversarial loss: -263.541656, acc: 1.000000]\n",
      "251: [discriminator loss: -93.206979, acc: 0.500000] [adversarial loss: -275.651794, acc: 1.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252: [discriminator loss: -96.888680, acc: 0.500000] [adversarial loss: -287.584930, acc: 1.000000]\n",
      "253: [discriminator loss: -100.690091, acc: 0.500000] [adversarial loss: -300.113708, acc: 1.000000]\n",
      "254: [discriminator loss: -100.538452, acc: 0.500000] [adversarial loss: -312.712280, acc: 1.000000]\n",
      "255: [discriminator loss: -110.202386, acc: 0.500000] [adversarial loss: -326.060059, acc: 1.000000]\n",
      "256: [discriminator loss: -101.582703, acc: 0.500000] [adversarial loss: -339.127686, acc: 1.000000]\n",
      "257: [discriminator loss: -113.433298, acc: 0.500000] [adversarial loss: -353.090637, acc: 1.000000]\n",
      "258: [discriminator loss: -114.580116, acc: 0.500000] [adversarial loss: -368.022919, acc: 1.000000]\n",
      "259: [discriminator loss: -116.316345, acc: 0.500000] [adversarial loss: -383.332581, acc: 1.000000]\n",
      "260: [discriminator loss: -115.524586, acc: 0.500000] [adversarial loss: -400.358276, acc: 1.000000]\n",
      "261: [discriminator loss: -123.643817, acc: 0.500000] [adversarial loss: -418.221741, acc: 1.000000]\n",
      "262: [discriminator loss: -121.592268, acc: 0.500000] [adversarial loss: -437.354614, acc: 1.000000]\n",
      "263: [discriminator loss: -122.190771, acc: 0.500000] [adversarial loss: -457.264893, acc: 1.000000]\n",
      "264: [discriminator loss: -128.416875, acc: 0.500000] [adversarial loss: -478.591675, acc: 1.000000]\n",
      "265: [discriminator loss: -127.151425, acc: 0.500000] [adversarial loss: -499.959106, acc: 1.000000]\n",
      "266: [discriminator loss: -127.154366, acc: 0.500000] [adversarial loss: -520.427002, acc: 1.000000]\n",
      "267: [discriminator loss: -113.653514, acc: 0.500000] [adversarial loss: -536.388550, acc: 1.000000]\n",
      "268: [discriminator loss: -127.161476, acc: 0.500000] [adversarial loss: -554.981689, acc: 1.000000]\n",
      "269: [discriminator loss: -132.951247, acc: 0.500000] [adversarial loss: -572.881165, acc: 1.000000]\n",
      "270: [discriminator loss: -134.494269, acc: 0.500000] [adversarial loss: -588.021057, acc: 1.000000]\n",
      "271: [discriminator loss: -133.616542, acc: 0.500000] [adversarial loss: -603.207825, acc: 1.000000]\n",
      "272: [discriminator loss: -124.720369, acc: 0.500000] [adversarial loss: -615.101562, acc: 1.000000]\n",
      "273: [discriminator loss: -130.085094, acc: 0.500000] [adversarial loss: -625.588501, acc: 1.000000]\n",
      "274: [discriminator loss: -128.861758, acc: 0.500000] [adversarial loss: -634.387573, acc: 1.000000]\n",
      "275: [discriminator loss: -132.543320, acc: 0.500000] [adversarial loss: -642.226379, acc: 1.000000]\n",
      "276: [discriminator loss: -131.825128, acc: 0.500000] [adversarial loss: -648.290466, acc: 1.000000]\n",
      "277: [discriminator loss: -126.672635, acc: 0.500000] [adversarial loss: -652.391296, acc: 1.000000]\n",
      "278: [discriminator loss: -130.047366, acc: 0.500000] [adversarial loss: -655.572632, acc: 1.000000]\n",
      "279: [discriminator loss: -139.233768, acc: 0.500000] [adversarial loss: -658.541504, acc: 1.000000]\n",
      "280: [discriminator loss: -139.564926, acc: 0.500000] [adversarial loss: -660.832214, acc: 1.000000]\n",
      "281: [discriminator loss: -136.243616, acc: 0.500000] [adversarial loss: -662.195862, acc: 1.000000]\n",
      "282: [discriminator loss: -141.848196, acc: 0.500000] [adversarial loss: -662.682861, acc: 1.000000]\n",
      "283: [discriminator loss: -145.424881, acc: 0.500000] [adversarial loss: -662.654602, acc: 1.000000]\n",
      "284: [discriminator loss: -143.700562, acc: 0.500000] [adversarial loss: -662.108948, acc: 1.000000]\n",
      "285: [discriminator loss: -147.135504, acc: 0.500000] [adversarial loss: -660.623840, acc: 1.000000]\n",
      "286: [discriminator loss: -150.301331, acc: 0.500000] [adversarial loss: -658.516968, acc: 1.000000]\n",
      "287: [discriminator loss: -145.054517, acc: 0.500000] [adversarial loss: -655.218018, acc: 1.000000]\n",
      "288: [discriminator loss: -153.404932, acc: 0.500000] [adversarial loss: -652.402344, acc: 1.000000]\n",
      "289: [discriminator loss: -143.182037, acc: 0.500000] [adversarial loss: -647.467407, acc: 1.000000]\n",
      "290: [discriminator loss: -150.906503, acc: 0.500000] [adversarial loss: -643.411499, acc: 1.000000]\n",
      "291: [discriminator loss: -159.409265, acc: 0.500000] [adversarial loss: -640.116638, acc: 1.000000]\n",
      "292: [discriminator loss: -165.155573, acc: 0.500000] [adversarial loss: -636.607544, acc: 1.000000]\n",
      "293: [discriminator loss: -162.120041, acc: 0.500000] [adversarial loss: -631.896179, acc: 1.000000]\n",
      "294: [discriminator loss: -163.551376, acc: 0.500000] [adversarial loss: -627.022644, acc: 1.000000]\n",
      "295: [discriminator loss: -168.155536, acc: 0.500000] [adversarial loss: -622.199951, acc: 1.000000]\n",
      "296: [discriminator loss: -173.719296, acc: 0.500000] [adversarial loss: -617.718811, acc: 1.000000]\n",
      "297: [discriminator loss: -177.016504, acc: 0.500000] [adversarial loss: -614.408081, acc: 1.000000]\n",
      "298: [discriminator loss: -192.902551, acc: 0.500000] [adversarial loss: -612.170471, acc: 1.000000]\n",
      "299: [discriminator loss: -185.853088, acc: 0.500000] [adversarial loss: -609.728088, acc: 1.000000]\n",
      "300: [discriminator loss: -175.477716, acc: 0.500000] [adversarial loss: -605.485107, acc: 1.000000]\n",
      "301: [discriminator loss: -185.025195, acc: 0.500000] [adversarial loss: -604.696167, acc: 1.000000]\n",
      "302: [discriminator loss: -187.002960, acc: 0.500000] [adversarial loss: -602.780762, acc: 1.000000]\n",
      "303: [discriminator loss: -197.836678, acc: 0.500000] [adversarial loss: -604.302856, acc: 1.000000]\n",
      "304: [discriminator loss: -201.139282, acc: 0.500000] [adversarial loss: -606.579285, acc: 1.000000]\n",
      "305: [discriminator loss: -209.101361, acc: 0.500000] [adversarial loss: -615.479370, acc: 1.000000]\n",
      "306: [discriminator loss: -216.625075, acc: 0.500000] [adversarial loss: -622.179443, acc: 1.000000]\n",
      "307: [discriminator loss: -224.325290, acc: 0.500000] [adversarial loss: -638.956299, acc: 1.000000]\n",
      "308: [discriminator loss: -217.864215, acc: 0.500000] [adversarial loss: -655.048706, acc: 1.000000]\n",
      "309: [discriminator loss: -223.540948, acc: 0.500000] [adversarial loss: -680.656128, acc: 1.000000]\n",
      "310: [discriminator loss: -229.664423, acc: 0.500000] [adversarial loss: -709.109253, acc: 1.000000]\n",
      "311: [discriminator loss: -241.489218, acc: 0.500000] [adversarial loss: -741.511841, acc: 1.000000]\n",
      "312: [discriminator loss: -247.575874, acc: 0.500000] [adversarial loss: -777.547241, acc: 1.000000]\n",
      "313: [discriminator loss: -243.807059, acc: 0.500000] [adversarial loss: -815.224060, acc: 1.000000]\n",
      "314: [discriminator loss: -248.232265, acc: 0.500000] [adversarial loss: -860.147095, acc: 1.000000]\n",
      "315: [discriminator loss: -262.532430, acc: 0.500000] [adversarial loss: -912.277588, acc: 1.000000]\n",
      "316: [discriminator loss: -254.146788, acc: 0.500000] [adversarial loss: -945.858459, acc: 1.000000]\n",
      "317: [discriminator loss: -270.241779, acc: 0.500000] [adversarial loss: -997.635681, acc: 1.000000]\n",
      "318: [discriminator loss: -266.367329, acc: 0.500000] [adversarial loss: -1045.729858, acc: 1.000000]\n",
      "319: [discriminator loss: -267.425397, acc: 0.500000] [adversarial loss: -1085.530762, acc: 1.000000]\n",
      "320: [discriminator loss: -258.711014, acc: 0.500000] [adversarial loss: -1110.791504, acc: 1.000000]\n",
      "321: [discriminator loss: -274.987589, acc: 0.500000] [adversarial loss: -1170.868042, acc: 1.000000]\n",
      "322: [discriminator loss: -274.943668, acc: 0.500000] [adversarial loss: -1217.202148, acc: 1.000000]\n",
      "323: [discriminator loss: -262.974847, acc: 0.500000] [adversarial loss: -1253.730835, acc: 1.000000]\n",
      "324: [discriminator loss: -276.863321, acc: 0.500000] [adversarial loss: -1286.290039, acc: 1.000000]\n",
      "325: [discriminator loss: -271.228426, acc: 0.500000] [adversarial loss: -1329.990967, acc: 1.000000]\n",
      "326: [discriminator loss: -278.357379, acc: 0.500000] [adversarial loss: -1370.065918, acc: 1.000000]\n",
      "327: [discriminator loss: -272.189099, acc: 0.500000] [adversarial loss: -1409.691650, acc: 1.000000]\n",
      "328: [discriminator loss: -269.431583, acc: 0.500000] [adversarial loss: -1427.399414, acc: 1.000000]\n",
      "329: [discriminator loss: -269.988623, acc: 0.500000] [adversarial loss: -1460.437988, acc: 1.000000]\n",
      "330: [discriminator loss: -278.138696, acc: 0.500000] [adversarial loss: -1487.792725, acc: 1.000000]\n",
      "331: [discriminator loss: -272.393779, acc: 0.500000] [adversarial loss: -1522.490112, acc: 1.000000]\n",
      "332: [discriminator loss: -272.155847, acc: 0.500000] [adversarial loss: -1536.193237, acc: 1.000000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333: [discriminator loss: -267.272650, acc: 0.500000] [adversarial loss: -1570.027954, acc: 1.000000]\n",
      "334: [discriminator loss: -274.026242, acc: 0.500000] [adversarial loss: -1593.861450, acc: 1.000000]\n",
      "335: [discriminator loss: -264.579298, acc: 0.500000] [adversarial loss: -1618.351074, acc: 1.000000]\n",
      "336: [discriminator loss: -264.736620, acc: 0.500000] [adversarial loss: -1621.848633, acc: 1.000000]\n",
      "337: [discriminator loss: -250.194495, acc: 0.500000] [adversarial loss: -1666.749268, acc: 1.000000]\n",
      "338: [discriminator loss: -259.747586, acc: 0.500000] [adversarial loss: -1670.439941, acc: 1.000000]\n",
      "339: [discriminator loss: -259.862570, acc: 0.500000] [adversarial loss: -1725.098511, acc: 1.000000]\n",
      "340: [discriminator loss: -256.532983, acc: 0.500000] [adversarial loss: -1741.707642, acc: 1.000000]\n",
      "341: [discriminator loss: -251.754651, acc: 0.500000] [adversarial loss: -1769.290649, acc: 1.000000]\n",
      "342: [discriminator loss: -235.045428, acc: 0.500000] [adversarial loss: -1792.227539, acc: 1.000000]\n",
      "343: [discriminator loss: -248.248773, acc: 0.500000] [adversarial loss: -1788.273315, acc: 1.000000]\n",
      "344: [discriminator loss: -241.910507, acc: 0.500000] [adversarial loss: -1817.532227, acc: 1.000000]\n",
      "345: [discriminator loss: -228.332391, acc: 0.500000] [adversarial loss: -1834.158936, acc: 1.000000]\n",
      "346: [discriminator loss: -246.409076, acc: 0.500000] [adversarial loss: -1856.837280, acc: 1.000000]\n",
      "347: [discriminator loss: -234.610135, acc: 0.500000] [adversarial loss: -1866.229980, acc: 1.000000]\n",
      "348: [discriminator loss: -228.699118, acc: 0.500000] [adversarial loss: -1888.804932, acc: 1.000000]\n",
      "349: [discriminator loss: -219.626758, acc: 0.500000] [adversarial loss: -1896.641602, acc: 1.000000]\n",
      "350: [discriminator loss: -201.486435, acc: 0.500000] [adversarial loss: -1926.838623, acc: 1.000000]\n",
      "351: [discriminator loss: -201.494409, acc: 0.500000] [adversarial loss: -1940.937012, acc: 1.000000]\n",
      "352: [discriminator loss: -202.276233, acc: 0.500000] [adversarial loss: -1954.858398, acc: 1.000000]\n",
      "353: [discriminator loss: -196.858914, acc: 0.500000] [adversarial loss: -1964.426392, acc: 1.000000]\n",
      "354: [discriminator loss: -189.861172, acc: 0.500000] [adversarial loss: -1989.149658, acc: 1.000000]\n",
      "355: [discriminator loss: -168.128101, acc: 0.500000] [adversarial loss: -2001.438110, acc: 1.000000]\n",
      "356: [discriminator loss: -173.365659, acc: 0.500000] [adversarial loss: -2011.322021, acc: 1.000000]\n",
      "357: [discriminator loss: -179.065851, acc: 0.500000] [adversarial loss: -2033.504150, acc: 1.000000]\n",
      "358: [discriminator loss: -166.069086, acc: 0.500000] [adversarial loss: -2029.738037, acc: 1.000000]\n",
      "359: [discriminator loss: -167.901187, acc: 0.500000] [adversarial loss: -2048.108887, acc: 1.000000]\n",
      "360: [discriminator loss: -145.920703, acc: 0.500000] [adversarial loss: -2067.202393, acc: 1.000000]\n",
      "361: [discriminator loss: -158.590094, acc: 0.500000] [adversarial loss: -2079.906006, acc: 1.000000]\n",
      "362: [discriminator loss: -148.836853, acc: 0.500000] [adversarial loss: -2081.645020, acc: 1.000000]\n",
      "363: [discriminator loss: -135.019244, acc: 0.500000] [adversarial loss: -2097.820312, acc: 1.000000]\n",
      "364: [discriminator loss: -127.496021, acc: 0.500000] [adversarial loss: -2097.790527, acc: 1.000000]\n",
      "365: [discriminator loss: -103.969214, acc: 0.500000] [adversarial loss: -2111.973389, acc: 1.000000]\n",
      "366: [discriminator loss: -120.988190, acc: 0.500000] [adversarial loss: -2109.553467, acc: 1.000000]\n",
      "367: [discriminator loss: -113.334009, acc: 0.500000] [adversarial loss: -2134.272217, acc: 1.000000]\n",
      "368: [discriminator loss: -93.092810, acc: 0.500000] [adversarial loss: -2140.194580, acc: 1.000000]\n",
      "369: [discriminator loss: -87.584601, acc: 0.500000] [adversarial loss: -2126.523926, acc: 1.000000]\n",
      "370: [discriminator loss: -95.194489, acc: 0.500000] [adversarial loss: -2143.687744, acc: 1.000000]\n",
      "371: [discriminator loss: -76.192169, acc: 0.500000] [adversarial loss: -2139.859375, acc: 1.000000]\n",
      "372: [discriminator loss: -85.617273, acc: 0.500000] [adversarial loss: -2143.284668, acc: 1.000000]\n",
      "373: [discriminator loss: -67.444330, acc: 0.500000] [adversarial loss: -2153.986816, acc: 1.000000]\n",
      "374: [discriminator loss: -64.780652, acc: 0.500000] [adversarial loss: -2150.292969, acc: 1.000000]\n",
      "375: [discriminator loss: -62.263879, acc: 0.500000] [adversarial loss: -2157.084961, acc: 1.000000]\n",
      "376: [discriminator loss: -62.311823, acc: 0.500000] [adversarial loss: -2150.807373, acc: 1.000000]\n",
      "377: [discriminator loss: -47.064771, acc: 0.500000] [adversarial loss: -2153.504639, acc: 1.000000]\n",
      "378: [discriminator loss: -40.174298, acc: 0.500000] [adversarial loss: -2151.093262, acc: 1.000000]\n",
      "379: [discriminator loss: -43.853467, acc: 0.500000] [adversarial loss: -2153.888184, acc: 1.000000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-da2b9ccda531>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# generate noise using uniform distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mfake_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# train the discriminator network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m     87\u001b[0m           method.__name__))\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1266\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1268\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1269\u001b[0m             \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1270\u001b[0m             \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    616\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# the generator image is saved every 500 steps\n",
    "save_interval = 500\n",
    "\n",
    "# noise vector to see how the generator output evolves during training\n",
    "noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n",
    "# number of elements in train dataset\n",
    "train_size = x_train.shape[0]\n",
    "# labels for real data\n",
    "real_labels = np.ones((batch_size, 1))\n",
    "for i in range(train_steps):\n",
    "    # train discriminator n_critic times\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    for _ in range(n_critic):\n",
    "        # train the discriminator for 1 batch\n",
    "        # 1 batch of real (label=1.0) and fake images (label=-1.0)\n",
    "        # randomly pick real images from dataset\n",
    "        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
    "        real_images = x_train[rand_indexes]\n",
    "        # generate fake images from noise using generator\n",
    "        # generate noise using uniform distribution\n",
    "        noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
    "        fake_images = generator.predict(noise)\n",
    "\n",
    "        # train the discriminator network\n",
    "        # real data label=1, fake data label=-1\n",
    "        # instead of 1 combined batch of real and fake images,\n",
    "        # train with 1 batch of real data first, then 1 batch\n",
    "        # of fake images.\n",
    "        # this tweak prevents the gradient from vanishing due to opposite\n",
    "        # signs of real and fake data labels (i.e. +1 and -1) and \n",
    "        # small magnitude of weights due to clipping.\n",
    "        real_loss, real_acc = discriminator.train_on_batch(real_images, real_labels)\n",
    "        fake_loss, fake_acc = discriminator.train_on_batch(fake_images, -real_labels)\n",
    "        # accumulate average loss and accuracy\n",
    "        loss += 0.5 * (real_loss + fake_loss)\n",
    "        acc += 0.5 * (real_acc + fake_acc)\n",
    "\n",
    "        # clip discriminator weights to satisfy Lipschitz constraint\n",
    "        for layer in discriminator.layers:\n",
    "            weights = layer.get_weights()\n",
    "            weights = [np.clip(weight, -clip_value, clip_value) for weight in weights]\n",
    "            layer.set_weights(weights)\n",
    "\n",
    "    # average loss and accuracy per n_critic training iterations\n",
    "    loss /= n_critic\n",
    "    acc /= n_critic\n",
    "    log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
    "\n",
    "    # train the adversarial network for 1 batch\n",
    "    # 1 batch of fake images with label=1.0\n",
    "    # since the discriminator weights are frozen in adversarial network\n",
    "    # only the generator is trained\n",
    "    # generate noise using uniform distribution\n",
    "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
    "    # train the adversarial network\n",
    "    # note that unlike in discriminator training,\n",
    "    # we do not save the fake images in a variable\n",
    "    # the fake images go to the discriminator input of the adversarial\n",
    "    # for classification\n",
    "    # fake images are labelled as real\n",
    "    # log the loss and accuracy\n",
    "    loss, acc = adversarial.train_on_batch(noise, real_labels)\n",
    "    log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n",
    "    print(log)\n",
    "    if (i + 1) % save_interval == 0:\n",
    "        if (i + 1) == train_steps:\n",
    "            show = True\n",
    "        else:\n",
    "            show = False\n",
    "\n",
    "    # plot generator images on a periodic basis\n",
    "    plot_images(generator, noise_input=noise_input, show=False, step=(i + 1), model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model after training the generator\n",
    "# the trained generator can be reloaded for future MNIST digit generation\n",
    "generator.save(model_name + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
