{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Activation, Dense, Input\n",
    "from tensorflow.keras.layers import Conv2D, Flatten\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(generator, noise_input, noise_label=None, noise_codes=None, show=False, step=0, model_name=\"gan\"):\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
    "    rows = int(math.sqrt(noise_input.shape[0]))\n",
    "    if noise_label is not None:\n",
    "        noise_input = [noise_input, noise_label]\n",
    "        if noise_codes is not None:\n",
    "            noise_input += noise_codes\n",
    "\n",
    "    images = generator.predict(noise_input)\n",
    "    plt.figure(figsize=(2.2, 2.2))\n",
    "    num_images = images.shape[0]\n",
    "    image_size = images.shape[1]\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, rows, i + 1)\n",
    "        image = np.reshape(images[i], [image_size, image_size])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(filename)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "# reshape data for CNN as (28, 28, 1) and normalize\n",
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"lsgan_mnist\"\n",
    "# network parameters\n",
    "# the latent or z vector is 100-dim\n",
    "latent_size = 100\n",
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 64\n",
    "lr = 2e-4\n",
    "decay = 6e-8\n",
    "train_steps = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 14, 14, 32)        832       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 64)          51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 1,080,577\n",
      "Trainable params: 1,080,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build discriminator model\n",
    "inputs = Input(shape=input_shape, name='discriminator_input')\n",
    "\n",
    "x = LeakyReLU(alpha=0.2)(inputs)\n",
    "x = Conv2D(filters=32, kernel_size=5, strides=2, padding='same')(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=5, strides=2, padding='same')(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=5, strides=2, padding='same')(x)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "x = Conv2D(filters=256, kernel_size=5, strides=1, padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(1)(x)\n",
    "discriminator = Model(inputs, outputs, name='discriminator')\n",
    "\n",
    "# [1] uses Adam, but discriminator converges easily with RMSprop\n",
    "optimizer = RMSprop(lr=lr, decay=decay)\n",
    "# LSGAN uses MSE loss [2]\n",
    "discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_input (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 49)                4949      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 1)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 7, 7, 1)           4         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 7, 7, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       3328      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 266,074\n",
      "Trainable params: 265,624\n",
      "Non-trainable params: 450\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build generator model\n",
    "input_shape = (latent_size, )\n",
    "image_resize = image_size // 4\n",
    "\n",
    "inputs = Input(shape=input_shape, name='z_input')\n",
    "x = Dense(image_resize * image_resize * 1)(inputs)\n",
    "x = Reshape((image_resize, image_resize, 1))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2DTranspose(filters=128, kernel_size=5, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2DTranspose(filters=64, kernel_size=5, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2DTranspose(filters=32, kernel_size=5, strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2DTranspose(filters=1, kernel_size=5, strides=1, padding='same')(x)\n",
    "x = Activation(activation='sigmoid')(x)\n",
    "\n",
    "generator = Model(inputs, x, name='generator')\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lsgan_mnist\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_input (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "generator (Model)            (None, 28, 28, 1)         266074    \n",
      "_________________________________________________________________\n",
      "discriminator (Model)        (None, 1)                 1080577   \n",
      "=================================================================\n",
      "Total params: 1,346,651\n",
      "Trainable params: 265,624\n",
      "Non-trainable params: 1,081,027\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build adversarial model = generator + discriminator\n",
    "optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
    "# freeze the weights of discriminator during adversarial training\n",
    "discriminator.trainable = False\n",
    "adversarial = Model(inputs, discriminator(generator(inputs)), name=model_name)\n",
    "# LSGAN uses MSE loss [2]\n",
    "adversarial.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "adversarial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [discriminator loss: 0.018497, acc: 1.000000] [adversarial loss: 0.279191, acc: 0.406250]\n",
      "1: [discriminator loss: 0.017713, acc: 1.000000] [adversarial loss: 0.082497, acc: 0.953125]\n",
      "2: [discriminator loss: 0.024931, acc: 1.000000] [adversarial loss: 0.232066, acc: 0.593750]\n",
      "3: [discriminator loss: 0.021450, acc: 1.000000] [adversarial loss: 0.035235, acc: 1.000000]\n",
      "4: [discriminator loss: 0.022464, acc: 1.000000] [adversarial loss: 0.338295, acc: 0.140625]\n",
      "5: [discriminator loss: 0.035219, acc: 1.000000] [adversarial loss: 0.022817, acc: 1.000000]\n",
      "6: [discriminator loss: 0.020089, acc: 1.000000] [adversarial loss: 0.254594, acc: 0.609375]\n",
      "7: [discriminator loss: 0.032478, acc: 0.992188] [adversarial loss: 0.013560, acc: 1.000000]\n",
      "8: [discriminator loss: 0.026180, acc: 1.000000] [adversarial loss: 0.277992, acc: 0.390625]\n",
      "9: [discriminator loss: 0.045784, acc: 0.984375] [adversarial loss: 0.022420, acc: 1.000000]\n",
      "10: [discriminator loss: 0.015323, acc: 1.000000] [adversarial loss: 0.163313, acc: 0.890625]\n",
      "11: [discriminator loss: 0.015464, acc: 1.000000] [adversarial loss: 0.026382, acc: 1.000000]\n",
      "12: [discriminator loss: 0.009691, acc: 1.000000] [adversarial loss: 0.114616, acc: 1.000000]\n",
      "13: [discriminator loss: 0.017785, acc: 1.000000] [adversarial loss: 0.006721, acc: 1.000000]\n",
      "14: [discriminator loss: 0.020505, acc: 1.000000] [adversarial loss: 0.229167, acc: 0.687500]\n",
      "15: [discriminator loss: 0.038405, acc: 0.992188] [adversarial loss: 0.006900, acc: 1.000000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c1ce532cfdf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# for classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# log the loss and accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madversarial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mlog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%s [adversarial loss: %f, acc: %f]\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1346\u001b[0m                                                     class_weight)\n\u001b[0;32m   1347\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\schphi\\.conda\\envs\\aml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# the generator image is saved every 500 steps\n",
    "save_interval = 500\n",
    "# noise vector to see how the generator output evolves during training\n",
    "noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n",
    "# number of elements in train dataset\n",
    "train_size = x_train.shape[0]\n",
    "for i in range(train_steps):\n",
    "    # train the discriminator for 1 batch\n",
    "    # 1 batch of real (label=1.0) and fake images (label=0.0)\n",
    "    # randomly pick real images from dataset\n",
    "    rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
    "    real_images = x_train[rand_indexes]\n",
    "    # generate fake images from noise using generator \n",
    "    # generate noise using uniform distribution\n",
    "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
    "    # generate fake images\n",
    "    fake_images = generator.predict(noise)\n",
    "    # real + fake images = 1 batch of train data\n",
    "    x = np.concatenate((real_images, fake_images))\n",
    "    # label real and fake images\n",
    "    # real images label is 1.0\n",
    "    y = np.ones([2 * batch_size, 1])\n",
    "    # fake images label is 0.0\n",
    "    y[batch_size:, :] = 0.0\n",
    "    # train discriminator network, log the loss and accuracy\n",
    "    loss, acc = discriminator.train_on_batch(x, y)\n",
    "    log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
    "\n",
    "    # train the adversarial network for 1 batch\n",
    "    # 1 batch of fake images with label=1.0\n",
    "    # since the discriminator weights are frozen in adversarial network\n",
    "    # only the generator is trained\n",
    "    # generate noise using uniform distribution\n",
    "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])\n",
    "    # label fake images as real or 1.0\n",
    "    y = np.ones([batch_size, 1])\n",
    "    # train the adversarial network \n",
    "    # note that unlike in discriminator training, \n",
    "    # we do not save the fake images in a variable\n",
    "    # the fake images go to the discriminator input of the adversarial\n",
    "    # for classification\n",
    "    # log the loss and accuracy\n",
    "    loss, acc = adversarial.train_on_batch(noise, y)\n",
    "    log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n",
    "    print(log)\n",
    "    if (i + 1) % save_interval == 0:\n",
    "        if (i + 1) == train_steps:\n",
    "            show = True\n",
    "        else:\n",
    "            show = False\n",
    "    \n",
    "        # plot generator images on a periodic basis\n",
    "        plot_images(generator, noise_input=noise_input, show=show, step=(i + 1), model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model after training the generator\n",
    "# the trained generator can be reloaded for future MNIST digit generation\n",
    "generator.save(model_name + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
